{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**win env**\n",
    "\n",
    "**it needs at least Spark standalone started on Windows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-01T03:41:16.429286Z",
     "start_time": "2018-01-01T03:41:11.021511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\dev\\\\spark-2.2.1-bin-hadoop2.7\\\\bin\\\\spark-submit.cmd', '--conf', 'spark.master=local[2]', '--conf', 'spark.app.name=test2', 'pyspark-shell']\n",
      "{'ALLUSERSPROFILE': 'C:\\\\ProgramData', 'APPDATA': 'C:\\\\Users\\\\nili6\\\\AppData\\\\Roaming', 'BTRACE_HOME': 'C:\\\\dev\\\\btrace-bin-1.3.9', 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files', 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files', 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files', 'COMPUTERNAME': 'PISCES-SURFACE-', 'COMSPEC': 'C:\\\\WINDOWS\\\\system32\\\\cmd.exe', 'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer', 'FPS_BROWSER_USER_PROFILE_STRING': 'Default', 'HADOOP_HOME': 'C:\\\\dev\\\\winutils\\\\hadoop-2.7.1', 'HOMEDRIVE': 'C:', 'HOMEPATH': '\\\\Users\\\\nili6', 'JAVA_HOME': 'C:\\\\dev\\\\jdk1.8.0_144', 'JUPYTER_CONFIG_DIR': 'C:\\\\nili\\\\my-git-projects\\\\learn_python\\\\jupyter_config', 'LOCALAPPDATA': 'C:\\\\Users\\\\nili6\\\\AppData\\\\Local', 'LOGONSERVER': '\\\\\\\\PISCES-SURFACE-', 'MOZ_PLUGIN_PATH': 'C:\\\\Program Files (x86)\\\\Foxit Software\\\\Foxit Reader\\\\plugins\\\\', 'NUMBER_OF_PROCESSORS': '4', 'ONEDRIVE': 'C:\\\\Users\\\\nili6\\\\OneDrive', 'OS': 'Windows_NT', 'PATH': 'C:\\\\dev\\\\anaconda3\\\\Library\\\\bin;C:\\\\dev\\\\anaconda3;C:\\\\dev\\\\anaconda3\\\\Scripts;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\Program Files\\\\Microsoft Windows Performance Toolkit\\\\;C:\\\\dev\\\\jdk1.8.0_144\\\\bin;C:\\\\dev\\\\apache-maven-3.5.2\\\\bin;C:\\\\Users\\\\nili6\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Program Files\\\\Microsoft VS Code\\\\bin;C:\\\\dev\\\\btrace-bin-1.3.9\\\\bin;C:\\\\dev\\\\ruby\\\\bin;C:\\\\dev\\\\spark-2.2.1-bin-hadoop2.7\\\\bin;C:\\\\dev\\\\winutils\\\\hadoop-2.7.1\\\\bin;', 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC', 'PROCESSOR_ARCHITECTURE': 'AMD64', 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 78 Stepping 3, GenuineIntel', 'PROCESSOR_LEVEL': '6', 'PROCESSOR_REVISION': '4e03', 'PROGRAMDATA': 'C:\\\\ProgramData', 'PROGRAMFILES': 'C:\\\\Program Files', 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)', 'PROGRAMW6432': 'C:\\\\Program Files', 'PROMPT': '$P$G', 'PSMODULEPATH': 'C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\WINDOWS\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules', 'PUBLIC': 'C:\\\\Users\\\\Public', 'SESSIONNAME': 'Console', 'SPARK_HOME': 'C:\\\\dev\\\\spark-2.2.1-bin-hadoop2.7', 'SYSTEMDRIVE': 'C:', 'SYSTEMROOT': 'C:\\\\WINDOWS', 'TEMP': 'C:\\\\temp', 'TMP': 'C:\\\\temp', 'USERDOMAIN': 'PISCES-SURFACE-', 'USERDOMAIN_ROAMINGPROFILE': 'PISCES-SURFACE-', 'USERNAME': 'nili6', 'USERPROFILE': 'C:\\\\Users\\\\nili6', 'VBOX_MSI_INSTALL_PATH': 'C:\\\\Program Files\\\\Oracle\\\\VirtualBox\\\\', 'VS100COMNTOOLS': 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio 10.0\\\\Common7\\\\Tools\\\\', 'WINDIR': 'C:\\\\WINDOWS', 'JPY_INTERRUPT_EVENT': '1884', 'IPY_INTERRUPT_EVENT': '1884', 'JPY_PARENT_PID': '1912', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline', '_PYSPARK_DRIVER_CALLBACK_HOST': '127.0.0.1', '_PYSPARK_DRIVER_CALLBACK_PORT': '8006'}\n"
     ]
    }
   ],
   "source": [
    "# spark bootstrap\n",
    "import os\n",
    "import sys\n",
    "#set working dir\n",
    "os.chdir('C:\\\\nili\\\\my-git-projects\\\\learn_python')\n",
    "# spark_path = 'C:/dev/spark-2.2.1-bin-hadoop2.7'\n",
    "# hadoop_path = 'C:/dev/winutils/hadoop-2.7.1'\n",
    "spark_path = \"C:\\\\dev\\\\spark-2.2.1-bin-hadoop2.7\"\n",
    "hadoop_path='C:\\\\dev\\\\winutils\\\\hadoop-2.7.1'\n",
    "os.environ['SPARK_HOME'] = spark_path\n",
    "os.environ['HADOOP_HOME'] = hadoop_path\n",
    "sys.path.append(spark_path + \"\\\\bin\")\n",
    "sys.path.append(spark_path + \"\\\\python\")\n",
    "sys.path.append(spark_path + \"\\\\python\\\\pyspark\")\n",
    "sys.path.append(spark_path + \"\\\\python\\\\lib\")\n",
    "sys.path.append(spark_path + \"\\\\python\\\\lib\\\\pyspark.zip\")\n",
    "sys.path.append(spark_path + \"\\\\python\\\\lib\\\\py4j-0.10.4-src.zip\")\n",
    "\n",
    "# With a SparkSession, applications can create DataFrames from an existing RDD, from a Hive table, or from Spark data sources.\n",
    "from pyspark.sql import SparkSession\n",
    "# !!! do not use space in parameter values\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[2]') \\\n",
    "    .appName(\"test2\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-01T03:41:29.541472Z",
     "start_time": "2018-01-01T03:41:25.542896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark is an existing SparkSession\n",
    "df = spark.read.json(\"data/people.json\")\n",
    "# Displays the content of the DataFrame to stdout\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
